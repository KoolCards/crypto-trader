{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Ethereum Price Exploration\n",
    "This starter notebook loads historical ETH prices from the local Parquet file so you can experiment with custom analysis in new cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ETH_PRICE_FILE = Path(\"./data/ethereum_price.parquet\")\n",
    "eth_prices = pd.read_parquet(ETH_PRICE_FILE)\n",
    "eth_prices\n",
    "\n",
    "# Basic shape and summary to confirm the data loaded as expected\n",
    "eth_prices.shape, eth_prices.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-notes",
   "metadata": {},
   "source": [
    "## Quick LSTM baseline\n",
    "This cell trains a small univariate LSTM on daily ETH returns to predict the next day's return. \\\n",
    "Requires `tensorflow` (e.g., `pip install tensorflow`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install tensorflow first: pip install tensorflow\") from exc\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install scikit-learn first: pip install scikit-learn\") from exc\n",
    "\n",
    "# Prepare returns\n",
    "prices = eth_prices.sort_values('date').copy()\n",
    "prices['return'] = prices['price'].pct_change()\n",
    "returns = prices['return'].dropna().to_numpy(dtype='float32')\n",
    "\n",
    "def build_sequences(arr: np.ndarray, window: int):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(arr)):\n",
    "        window_slice = arr[i-window:i]\n",
    "        target_ret = arr[i]\n",
    "        if target_ret >= 0.02:\n",
    "            label = 1  # >= +2%\n",
    "        elif target_ret <= -0.02:\n",
    "            label = 2  # <= -2%\n",
    "        else:\n",
    "            label = 0  # between -2% and +2%\n",
    "        X.append(window_slice)\n",
    "        y.append(label)\n",
    "    X = np.array(X, dtype='float32')[..., np.newaxis]\n",
    "    y = np.array(y, dtype='int64')\n",
    "    return X, y\n",
    "\n",
    "def apply_confidence_threshold(prob_array: np.ndarray, threshold: float) -> np.ndarray:\n",
    "    if prob_array.size == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    classes = np.argmax(prob_array, axis=1)\n",
    "    confidences = prob_array[np.arange(len(prob_array)), classes]\n",
    "    final = np.zeros_like(classes)\n",
    "    for idx, (cls, conf) in enumerate(zip(classes, confidences)):\n",
    "        if cls == 0:\n",
    "            final[idx] = 0\n",
    "        elif conf >= threshold:\n",
    "            final[idx] = cls\n",
    "        else:\n",
    "            final[idx] = 0\n",
    "    return final\n",
    "\n",
    "SEQ_LEN = 30\n",
    "CONF_THRESHOLD = 0.7  # require high confidence before predicting +/- 2%\n",
    "X, y = build_sequences(returns, SEQ_LEN)\n",
    "if len(X) < 10:\n",
    "    raise ValueError('Not enough data to build sequences; collect more daily prices.')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# 80/10/10 split with shuffling\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=RANDOM_STATE, shuffle=True\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1111, random_state=RANDOM_STATE, shuffle=True\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN, 1)),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(3, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0) if len(X_test) else (float('nan'), float('nan'))\n",
    "test_probs = model.predict(X_test, verbose=0) if len(X_test) else np.empty((0, 3))\n",
    "raw_test_classes = np.argmax(test_probs, axis=1) if len(test_probs) else np.array([], dtype=int)\n",
    "threshold_test_classes = apply_confidence_threshold(test_probs, CONF_THRESHOLD)\n",
    "\n",
    "if len(raw_test_classes):\n",
    "    print('--- Raw test classification report ---')\n",
    "    print(classification_report(y_test, raw_test_classes, digits=3))\n",
    "    print('--- Thresholded test classification report ---')\n",
    "    print(classification_report(y_test, threshold_test_classes, digits=3))\n",
    "    print('Confusion matrix (thresholded):')\n",
    "    print(confusion_matrix(y_test, threshold_test_classes, labels=[0, 1, 2]))\n",
    "    confident_preds = np.sum(threshold_test_classes != 0)\n",
    "    print(f'Confident +/- predictions on test set: {confident_preds} / {len(threshold_test_classes)}')\n",
    "\n",
    "probs_next = model.predict(X[-1:], verbose=0)[0] if len(X) else np.array([np.nan] * 3)\n",
    "next_class_raw = int(np.argmax(probs_next)) if np.all(np.isfinite(probs_next)) else -1\n",
    "next_class_thresholded = apply_confidence_threshold(probs_next[np.newaxis, :], CONF_THRESHOLD)[0] if np.all(np.isfinite(probs_next)) else -1\n",
    "class_names = {0: 'between -2% and +2%', 1: '>= +2%', 2: '<= -2%'}\n",
    "last_price = float(prices['price'].iloc[-1]) if len(prices) else float('nan')\n",
    "\n",
    "print(f'Train samples: {len(X_train)}, Val samples: {len(X_val)}, Test samples: {len(X_test)}')\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')\n",
    "print('Next-day raw class:', next_class_raw, '-', class_names.get(next_class_raw, 'n/a'))\n",
    "print('Next-day thresholded class:', next_class_thresholded, '-', class_names.get(next_class_thresholded, 'n/a'))\n",
    "print('Next-day class probabilities:', probs_next)\n",
    "print(f'Last close: {last_price:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f0045",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}